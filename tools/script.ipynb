{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd05743a7ad93919297537dfa383234c159c87cd87de3218c6c4524fd79fd9e5a77",
   "display_name": "Python 3.9.1 64-bit ('.venv')"
  },
  "metadata": {
   "interpreter": {
    "hash": "a86ff4ae3ee3a1b21f325b1ece796c8b39c5652a82900a8a39a5348e73740373"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Loading the corpus"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "75754 words loaded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "with open('corpuses/coed.txt', encoding='utf-8') as f:\n",
    "    words = [line.rstrip() for line in f]\n",
    "\n",
    "print(f'{len(words)} words loaded.')"
   ]
  },
  {
   "source": [
    "# Filtering the corpus "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "32706 valid words\n"
     ]
    }
   ],
   "source": [
    "# Remove all words with non-alpha characters\n",
    "import string\n",
    "valid_letters = set([letter for letter in string.ascii_lowercase])\n",
    "words = list(filter(lambda word: all((letter in valid_letters for letter in word)), words))\n",
    "# Remove words shorter than 3 characters, and larger than 9 characters\n",
    "words = list(filter(lambda word: len(word) >= 3 and len(word) <= 9, words))\n",
    "# Remove all capitalised words \n",
    "words = list(filter(lambda word: word[0].islower(), words))\n",
    "\n",
    "words = set(words)\n",
    "\n",
    "with open('corpuses/coed_adverbs_with_ly.txt', encoding='utf-8') as f:\n",
    "    adverbs_with_ly = set([line.rstrip() for line in f])\n",
    "    words = words - adverbs_with_ly\n",
    "\n",
    "with open('corpuses/coed_plurals.txt', encoding='utf-8') as f:\n",
    "    plurals = set([line.rstrip() for line in f])\n",
    "    words = words - plurals\n",
    "\n",
    "with open('corpuses/coed_tenses_and_participles.txt', encoding='utf-8') as f:\n",
    "    tenses_and_participles = set([line.rstrip() for line in f])\n",
    "    words = words - tenses_and_participles\n",
    "\n",
    "with open('corpuses/coed_abbreviations.txt', encoding='utf-8') as f:\n",
    "    abbreviations = set([line.rstrip() for line in f])\n",
    "    words = words - abbreviations\n",
    "\n",
    "with open('corpuses/google_profane_words.txt', encoding='utf-8') as f:\n",
    "    profanities = set([line.rstrip() for line in f])\n",
    "    words = words - profanities\n",
    "\n",
    "words = sorted(list(words))\n",
    "\n",
    "print(f\"{len(words)} valid words\")"
   ]
  },
  {
   "source": [
    "# Save as a new corpus "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpuses/glypoon.txt', 'w+', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(sorted(words)))"
   ]
  },
  {
   "source": [
    "# Group words by length"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       word  length\n",
       "0  aardvark       8\n",
       "1  aardwolf       8\n",
       "2     aargh       5\n",
       "3     abaca       5\n",
       "4     aback       5"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aardvark</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>aardwolf</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>aargh</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>abaca</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>aback</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "import pandas \n",
    "\n",
    "words_df = pandas.DataFrame(words, columns=['word'])\n",
    "words_df['length'] = words_df.apply(lambda row: len(row['word']), axis=1)\n",
    "\n",
    "words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   length                                              words  count\n",
       "0       3  [ace, act, add, ado, aft, aga, age, ago, aha, ...    766\n",
       "1       4  [abed, abet, able, abut, acer, ache, achy, aci...   2627\n",
       "2       5  [aargh, abaca, aback, abaft, abase, abash, aba...   4233\n",
       "3       6  [abacus, abatis, abbacy, abbess, abdabs, abduc...   5896\n",
       "4       7  [abalone, abandon, abashed, abaxial, abdomen, ...   6585\n",
       "5       8  [aardvark, aardwolf, abattoir, abbatial, abdic...   6631\n",
       "6       9  [abandoned, abdominal, abhorrent, ablutions, a...   6039"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>length</th>\n      <th>words</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>[ace, act, add, ado, aft, aga, age, ago, aha, ...</td>\n      <td>766</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>[abed, abet, able, abut, acer, ache, achy, aci...</td>\n      <td>2627</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>[aargh, abaca, aback, abaft, abase, abash, aba...</td>\n      <td>4233</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>[abacus, abatis, abbacy, abbess, abdabs, abduc...</td>\n      <td>5896</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>[abalone, abandon, abashed, abaxial, abdomen, ...</td>\n      <td>6585</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>8</td>\n      <td>[aardvark, aardwolf, abattoir, abbatial, abdic...</td>\n      <td>6631</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>9</td>\n      <td>[abandoned, abdominal, abhorrent, ablutions, a...</td>\n      <td>6039</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df_group_by_length = words_df.groupby(by='length')['word'] \\\n",
    "                        .apply(list) \\\n",
    "                        .reset_index(name='words')\n",
    "\n",
    "df_group_by_length['count'] = df_group_by_length.apply(lambda row: len(row['words']), axis=1)\n",
    "\n",
    "df_group_by_length"
   ]
  },
  {
   "source": [
    "# Select a random word of length K"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fanlight\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "K = 8\n",
    "\n",
    "words_with_length_k = df_group_by_length.loc[df_group_by_length['length'] == K]['words'].values[0]\n",
    "chosen_word = random.choice(words_with_length_k)\n",
    "\n",
    "print(chosen_word)"
   ]
  },
  {
   "source": [
    "# Find pangram words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5 possible solution(s) found.\nFull word: fanlight\nCenter letter: f\n24 answers: fail, fain, faint, faith, fang, fanlight, fatling, fiat, fight, filth, final, fitna, flag, flan, flat, flight, fling, flint, flit, gift, haft, half, lift, naif\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "MIN_ANSWER_LENGTH = 4  # Minimum answer length\n",
    "MIN_NUM_ANSWERS = 20  # Minimum number of answers\n",
    "MAX_NUM_ANSWERS = 35  # Maximum number of answers\n",
    "\n",
    "answers_by_keyword = {}\n",
    "for keyword in chosen_word:  # For each possible letter to use as the 'center word' \n",
    "    answers_by_keyword[keyword] = []\n",
    "    for word in words:\n",
    "        if len(word) < MIN_ANSWER_LENGTH:\n",
    "            continue\n",
    "        if keyword not in word:\n",
    "            continue\n",
    "        if not Counter(word) - Counter(chosen_word):\n",
    "            answers_by_keyword[keyword].append(word)\n",
    "\n",
    "solutions = []\n",
    "for keyword, answers in answers_by_keyword.items():\n",
    "    if len(answers) >= MIN_NUM_ANSWERS and len(answers) <= MAX_NUM_ANSWERS:\n",
    "        solutions.append((chosen_word, keyword, sorted(answers)))\n",
    "\n",
    "print(f'{len(solutions)} possible solution(s) found.')\n",
    "if solutions:\n",
    "    solution = random.choice(solutions)\n",
    "\n",
    "    print(f'Full word: {solution[0]}')\n",
    "    print(f'Center letter: {solution[1]}')\n",
    "    print(f'{len(solution[2])} answers: {\", \".join(solution[2])}')"
   ]
  },
  {
   "source": [
    "# Export as a JSON file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "OUTPUT_FILE_NAME = 'answers.json'\n",
    "\n",
    "letters = [char for char in solution[0]]\n",
    "random.shuffle(letters)\n",
    "letters.remove(solution[1])\n",
    "letters.insert(0, solution[1])\n",
    "\n",
    "json_solution = {\n",
    "    'letters': letters,\n",
    "    'answers': solution[2]\n",
    "}\n",
    "\n",
    "with open(OUTPUT_FILE_NAME, 'w+') as solution_file:\n",
    "    json.dump(json_solution, solution_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}